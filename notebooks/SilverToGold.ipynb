{"cells":[{"cell_type":"markdown","source":["# Incremental files ingestion from Azure Blob Storage to Microsoft Fabric Lakehouse using PySpark Notebooks"],"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"nteract":{"transient":{"deleting":false}}},"id":"a64a9541-b201-4f9e-9eb0-d8d88ca4bd2f"},{"cell_type":"markdown","source":["> <br> This project uses the database provided by the government of Brazil called **Cadastro Geral de Empregados e Desempregados (CAGED)** (General Register of Employed and Unemployed).<br><br>"],"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"nteract":{"transient":{"deleting":false}}},"id":"070f080b-9110-4a4e-a126-d16476525595"},{"cell_type":"markdown","source":["**Notebook**: SilverToGold  \n","**Description**: This PySpark notebook performs incremental ingestion of rows from the Silver layer of the Lakehouse to the Gold layer. It uses the ingestion date of each original file as a reference."],"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"nteract":{"transient":{"deleting":false}}},"id":"8daf5425-d92f-456e-9abf-143818a6f8c2"},{"cell_type":"code","source":["# Imports\n","from datetime import datetime\n","from pyspark.sql import functions as F\n","from pyspark.sql.types import *\n","\n","# Set case sensitive for table and column names\n","spark.conf.set('spark.sql.caseSensitive', True)"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"1f9ac1aa-0653-46aa-8a6c-99cc468b7813"},{"cell_type":"markdown","source":["## Parameters"],"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"nteract":{"transient":{"deleting":false}}},"id":"d8ebfc8c-8f44-4f09-bf91-d06f8889a0e7"},{"cell_type":"code","source":["# Lakehouse paths\n","silver_meta_table       = \"CagedSilverMeta\"\n","silver_table            = \"CagedSilver\"\n","gold_meta_table         = \"CagedGoldMeta\"  # Control table to track from Silver (Curated) to Gold\n","gold_table              = \"CagedGold\"      # Gold layer of data (Aggregated)"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"9a1a64cf-6430-4e11-b238-a0932766e91b"},{"cell_type":"markdown","source":["## Prepare, create and load schemas and tables"],"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"nteract":{"transient":{"deleting":false}}},"id":"2fcc8560-b6c3-471d-971b-16326f1f491b"},{"cell_type":"code","source":["# Define schema to gold_meta_table \n","gold_meta_schema = StructType([\n","    StructField(\"file_path\", StringType(), False),\n","    StructField(\"source_modified_at\", TimestampType(), False),\n","    StructField(\"processed_at\", TimestampType(), True),\n","])\n","\n","# Create the gold_meta_table (if not exists)\n","spark.createDataFrame([], gold_meta_schema) \\\n","    .write.format(\"delta\") \\\n","    .mode(\"ignore\") \\\n","    .saveAsTable(gold_meta_table)\n","\n","# Define schema to gold_table with types and PascalCase column names\n","gold_schema = StructType([\n","    StructField(\"CompetenciaMov\", DateType(), True),  \n","    StructField(\"Regiao\", StringType(), True),\n","    StructField(\"Uf\", StringType(), True),\n","    StructField(\"Secao\", StringType(), True),\n","    StructField(\"Subclasse\", StringType(), True),\n","    StructField(\"FaixaEtaria\", IntegerType(), True),\n","    StructField(\"GrauInstrucao\", IntegerType(), True),\n","    StructField(\"RacaCor\", StringType(), True),\n","    StructField(\"Sexo\", StringType(), True),\n","    StructField(\"TamEstabJan\", StringType(), True),\n","    StructField(\"Admissoes\", IntegerType(), True),\n","    StructField(\"Desligamentos\", IntegerType(), True),\n","    # Control Columns\n","    StructField(\"FilePath\", StringType(), False),\n","    StructField(\"SourceModifiedAt\", TimestampType(), False)\n","])\n","\n","# Create the gold_table (if not exists)\n","spark.createDataFrame([], gold_schema) \\\n","    .write.format(\"delta\") \\\n","    .mode(\"ignore\") \\\n","    .partitionBy(\"CompetenciaMov\") \\\n","    .saveAsTable(gold_table)\n","\n","# Load silver_table and gold_meta_table\n","df_silver = spark.table(silver_table)\n","df_gold_meta = spark.table(gold_meta_table)\n","\n","# Consolidate the files already processed on silver\n","df_gold_meta_latest = df_gold_meta.groupBy(\"file_path\").agg(\n","    F.max(\"source_modified_at\").alias(\"last_processed_source_mtime\")\n",")"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"0655bf37-aa59-47af-8577-592edc48cdef"},{"cell_type":"markdown","source":["## "],"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"nteract":{"transient":{"deleting":false}}},"id":"9dd46f51-49a2-4c12-960c-9e715ac492a3"},{"cell_type":"markdown","source":["## Find candidates to load"],"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"nteract":{"transient":{"deleting":false}}},"id":"eb4b1bfd-4b60-49ea-b1a3-27258a517899"},{"cell_type":"code","source":["# Identify candidate rows for ingestion (newers or updated)\n","df_gold_candidates = (\n","    df_silver\n","    .join(df_gold_meta_latest, df_silver.FilePath == df_gold_meta_latest.file_path, \"left\")\n","    .filter(\n","        F.col(\"last_processed_source_mtime\").isNull() |\n","        (F.col(\"SourceModifiedAt\") > F.coalesce(F.col(\"last_processed_source_mtime\"), F.lit(\"1970-01-01\")))\n","    )\n","    .select(\n","        df_silver.FilePath,\n","        df_silver.SourceModifiedAt,\n","        # Select all columns except\n","        *[F.col(col) for col in df_silver.columns if col not in [\"FilePath\", \"SourceModifiedAt\"]]\n","    )\n",")\n","\n","# Count candidates\n","print(f\"Rows to process from Silver to Gold: {df_gold_candidates.count()}\")\n"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"572ee654-311e-4abe-ba2e-65aa2e299c82"},{"cell_type":"markdown","source":["## Process the load"],"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"nteract":{"transient":{"deleting":false}}},"id":"3a669acb-f952-42d8-8eb3-b1e33457a337"},{"cell_type":"code","source":["# Process candidate rows\n","\n","if df_gold_candidates.rdd.isEmpty():\n","    print(\"Nothing to load. Skipping...\")\n","else:\n","    # Create age groups and aggregate data to BI\n","    df_aggregated = df_gold_candidates.withColumn(\n","        \"FaixaEtaria\",\n","        F.when(F.col(\"Idade\") < 18, 1)\n","          .when((F.col(\"Idade\") >= 18) & (F.col(\"Idade\") <= 24), 2)\n","          .when((F.col(\"Idade\") >= 25) & (F.col(\"Idade\") <= 29), 3)\n","          .when((F.col(\"Idade\") >= 30) & (F.col(\"Idade\") <= 39), 4)\n","          .when((F.col(\"Idade\") >= 40) & (F.col(\"Idade\") <= 49), 5)\n","          .when((F.col(\"Idade\") >= 50) & (F.col(\"Idade\") <= 64), 6)\n","          .otherwise(7)\n","    ).withColumn( \n","        \"Admissoes\", \n","        F.when(F.col(\"SaldoMovimentacao\") == 1, 1).otherwise(0)\n","    ).withColumn(\n","        \"Desligamentos\", \n","        F.when(F.col(\"SaldoMovimentacao\") == -1, 1).otherwise(0)\n","    ).drop(*[\"Idade\", \"SaldoMovimentacao\"]).groupBy(\n","        \"CompetenciaMov\", \"Regiao\", \"Uf\", \"Secao\", \n","        \"Subclasse\", \"FaixaEtaria\", \"GrauInstrucao\", \"RacaCor\", \n","        \"Sexo\", \"TamEstabJan\", \"FilePath\", \"SourceModifiedAt\"\n","    ).agg(\n","        F.sum(\"Admissoes\").alias(\"Admissoes\"),\n","        F.sum(\"Desligamentos\").alias(\"Desligamentos\")\n","    )\n","\n","    # Merge to update or insert into gold table\n","    df_aggregated.createOrReplaceTempView(\"source_data\")\n","    spark.sql(f\"\"\"\n","    MERGE INTO {gold_table} AS target\n","    USING source_data AS source\n","    ON target.FilePath = source.FilePath AND target.CompetenciaMov = source.CompetenciaMov\n","    WHEN MATCHED AND target.SourceModifiedAt < source.SourceModifiedAt THEN\n","        UPDATE SET *\n","    WHEN NOT MATCHED THEN\n","        INSERT *\n","    \"\"\")\n","\n","    # Optimize the gold_table to reduce small files\n","    spark.sql(f\"OPTIMIZE {gold_table}\")\n","\n","    # Record metadados\n","    processed_files = df_aggregated.select(\"FilePath\", \"SourceModifiedAt\").distinct().collect()\n","    df_processed = spark.createDataFrame(\n","        [{\"file_path\": row[\"FilePath\"], \"source_modified_at\": row[\"SourceModifiedAt\"], \"processed_at\": datetime.now()} for row in processed_files],\n","        schema=gold_meta_schema\n","    )\n","    df_processed.write.format(\"delta\").mode(\"append\").saveAsTable(gold_meta_table)\n","\n","    print(\"Gold zone updated successfully!\")"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"95707bd2-3afa-4ebc-a4bb-a37339fcb292"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"display_name":"synapse_pyspark","name":"synapse_pyspark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{"lakehouse":{"default_lakehouse":"c8ff1e00-35ab-4743-9399-2504f666c867","default_lakehouse_name":"LK_SparkBlobMedallion","default_lakehouse_workspace_id":"22faa9df-ae9d-4b3e-8f77-9d47b85702d9","known_lakehouses":[{"id":"c8ff1e00-35ab-4743-9399-2504f666c867"}]}}},"nbformat":4,"nbformat_minor":5}